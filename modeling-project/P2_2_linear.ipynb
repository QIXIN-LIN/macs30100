{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "note: because the pre-processing 90k+ images is time-consuming, I would use a subset I create to complete this assignment. This subset has average distribution label for gender-race combination to avoid potential bias."
      ],
      "metadata": {
        "id": "8OFYV1Sk-waA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "hCzTxTeF-yBa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the image dataset\n",
        "\n",
        "# Just run once\n",
        "\n",
        "'''\n",
        "%cd /content\n",
        "!gdown --id '13shxKy6WSeAa7dPhccnSG9aoFZ76lVPT' --output fairface-img-margin025-trainval.zip\n",
        "!unzip fairface-img-margin025-trainval.zip\n",
        "'''"
      ],
      "metadata": {
        "id": "6nl6lBY1ibac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116bd3e1-0cdb-432a-88fd-be3a01a21a3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13shxKy6WSeAa7dPhccnSG9aoFZ76lVPT\n",
            "From (redirected): https://drive.google.com/uc?id=13shxKy6WSeAa7dPhccnSG9aoFZ76lVPT&confirm=t&uuid=5cd3b74e-90fa-4b2e-82b9-803607455ee4\n",
            "To: /content/fairface-img-margin025-trainval.zip\n",
            "100% 578M/578M [00:06<00:00, 83.7MB/s]\n",
            "Archive:  fairface-img-margin025-trainval.zip\n",
            "replace train/1346.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the csv label file for the subset\n",
        "\n",
        "# Just run once\n",
        "\n",
        "'''\n",
        "%cd /content\n",
        "!gdown --id '1bwKY_aVMRIQ_IcrFnpsTG-E3ZE7iAM8t' --output fairface_subset.csv\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqmf7RP8_pmg",
        "outputId": "2876fc37-96b5-4734-e16d-fe6d03161301"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bwKY_aVMRIQ_IcrFnpsTG-E3ZE7iAM8t\n",
            "To: /content/fairface_subset.csv\n",
            "100% 279k/279k [00:00<00:00, 87.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels\n",
        "file_path = 'fairface_subset.csv'\n",
        "labels_df = pd.read_csv(file_path)\n",
        "\n",
        "labels_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRS2uGMhjtdm",
        "outputId": "2d388d1c-75b2-43fd-953b-677c92c5c6df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6300, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images\n",
        "def load_and_preprocess_image(image_path):\n",
        "  # Load image\n",
        "  image = Image.open(image_path)\n",
        "  image = image.resize((64, 64))\n",
        "\n",
        "  # Convert to grayscale\n",
        "  image = image.convert('L')\n",
        "\n",
        "  # Convert to numpy array and flatten\n",
        "  image_array = np.array(image).flatten()\n",
        "  return image_array\n",
        "\n",
        "\n",
        "images = [load_and_preprocess_image(f'{fname}') for fname in labels_df['file']]"
      ],
      "metadata": {
        "id": "mpe4JxSakrrF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature matrix X and labels y\n",
        "X = np.stack(images, axis=0)\n",
        "y = labels_df['gender'].values\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DtYogBlCAXBr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the logistic regression model (with l1 penalty)\n",
        "model_l1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model_l1.fit(X_train, y_train)\n",
        "\n",
        "# Get the score\n",
        "model_l1.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdShvlz-OES_",
        "outputId": "db36475c-1a96-4973-95cc-ca2319f7b017"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6158730158730159"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the logistic regression model (with l2 penalty)\n",
        "model_l2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "# Get the score\n",
        "model_l2.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgUYJij-RbG3",
        "outputId": "b3dbe8a4-14b7-4c64-f09d-0478561c468b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6047619047619047"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another solver\n",
        "model_l2_lbfgs = LogisticRegression(random_state=0, solver='lbfgs', penalty='l2', C=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model_l2_lbfgs.fit(X_train, y_train)\n",
        "\n",
        "# Get the score\n",
        "model_l2_lbfgs.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mmG08cqSZk1",
        "outputId": "28a3e8ee-184c-4810-a863-a870037f0aa2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6849206349206349"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another solver\n",
        "model_l1_saga = LogisticRegression(random_state=0, solver='saga', penalty='l1', C=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model_l1_saga.fit(X_train, y_train)\n",
        "\n",
        "# Get the score\n",
        "model_l1_saga.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6u2IxXZstQ",
        "outputId": "660c65fc-41d2-4530-9afb-76ab223b4ca1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7277777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, 'saga' with l1 penalty has decent running time and highest score. But there's a warning about interation. So I will try different max_iter. Than I will try different C values."
      ],
      "metadata": {
        "id": "QMDlwCZ2Y2gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different max_iter\n",
        "max_iter_values = [10, 20, 50, 100, 200, 500]\n",
        "\n",
        "for max_iter in max_iter_values:\n",
        "    model = LogisticRegression(random_state=0, solver='saga', penalty='l1',\n",
        "            C=1.0, max_iter=max_iter)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    train_score = model.score(X_train, y_train)\n",
        "    test_score = model.score(X_test, y_test)\n",
        "\n",
        "    print(f\"max_iter: {max_iter}, Training score: {train_score:.4f}, Test score: {test_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSgi8PYoaS9G",
        "outputId": "11e48e98-b6b9-4bc0-ce86-d5a381a5c7f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter: 10, Training score: 0.7548, Test score: 0.7278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter: 20, Training score: 0.7673, Test score: 0.7349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter: 50, Training score: 0.7913, Test score: 0.7325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter: 100, Training score: 0.8024, Test score: 0.7278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_iter: 200, Training score: 0.8177, Test score: 0.7190\n",
            "max_iter: 500, Training score: 0.8437, Test score: 0.7032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting outcomes - even the model still didn't converge, the test score decreased. So I will give 20 and 50 further try."
      ],
      "metadata": {
        "id": "rnVtogGpludH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different regularization strengths\n",
        "for C_value in [0.01, 0.1, 1, 10, 100]:\n",
        "    model = LogisticRegression(C=C_value, penalty='l1', solver='saga', max_iter=20)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"C={C_value}, Training score: {model.score(X_train, y_train):.4f}, Test score: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1YGgvxhS7tL",
        "outputId": "1b8f8659-ef3b-4e6e-e9d4-b2574ea42d06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, Training score: 0.7669, Test score: 0.7341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.1, Training score: 0.7661, Test score: 0.7333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1, Training score: 0.7688, Test score: 0.7317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=10, Training score: 0.7683, Test score: 0.7357\n",
            "C=100, Training score: 0.7675, Test score: 0.7341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different regularization strengths\n",
        "for C_value in [0.01, 0.1, 1, 10, 100]:\n",
        "    model = LogisticRegression(C=C_value, penalty='l1', solver='saga', max_iter=50)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"C={C_value}, Training score: {model.score(X_train, y_train):.4f}, Test score: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW9OdH0DmDwk",
        "outputId": "761c47a0-8a44-48ad-9155-2d29c51a404d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, Training score: 0.7865, Test score: 0.7365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.1, Training score: 0.7911, Test score: 0.7341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1, Training score: 0.7917, Test score: 0.7310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=10, Training score: 0.7919, Test score: 0.7325\n",
            "C=100, Training score: 0.7927, Test score: 0.7325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best-performing logistic regression model on the dataset incorporates an L1 penalty with a regularization strength of C=0.01, using the 'saga' solver, and allowing for 50 iterations. This setup suggests that the data benefits from a stronger regularization, which helps in reducing overfitting by penalizing less important features.\n",
        "\n",
        "The 'saga' solver was effective for my needs, likely due to its efficiency with large datasets and its ability to handle L1 penalties well."
      ],
      "metadata": {
        "id": "3LNEV4LZqGOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discuss about pros ann cons of models\n",
        "\n",
        "## Solvers:\n",
        "\n",
        "### liblinear:\n",
        "+ Pros:\n",
        " + It's a good choice for small to medium datasets.\n",
        " + It supports both L1 and L2 regularization.\n",
        " + It's easy to use and interpret.\n",
        "+ Cons:\n",
        " + Not suitable for very large datasets because it can be slow.\n",
        " + It does not support multinomial logistic regression; it handles multiclass using a one-vs-rest approach, which can be less efficient.\n",
        " + It may have convergence issues with L1 regularization on non-separable data or with insufficient iterations.\n",
        "\n",
        "### saga:\n",
        "+ Pros:\n",
        " + Designed for large datasets with many samples.\n",
        " + Faster for large datasets due to incremental, gradient-based optimization.\n",
        " + saga supports both L1 and L2 regularization, making it versatile.\n",
        "+ Cons:\n",
        " + May take longer to converge on smaller datasets.\n",
        " + Requires features to be scaled (e.g., using StandardScaler).\n",
        "\n",
        "## Regularization (Penalty) Techniques:\n",
        "\n",
        "### L1 Regularization (Lasso):\n",
        "+ Pros:\n",
        " + Can lead to sparse models where some coefficients can become zero.\n",
        " + Useful for feature selection because it can eliminate some features entirely.\n",
        "+ Cons:\n",
        " + Can lead to a less stable solution path for coefficients.\n",
        " + Not supported by all solvers.\n",
        "\n",
        "### L2 Regularization (Ridge):\n",
        "+ Pros:\n",
        " + Tends to give better results for features with real predictive power.\n",
        " + The model is less likely to fit noise in the data.\n",
        " + Supported by most solvers.\n",
        "+ Cons:\n",
        " + Does not reduce coefficients to zero, which means it does not perform feature selection.\n",
        " + May lead to smaller coefficients on average, as it shrinks all coefficients equally.\n"
      ],
      "metadata": {
        "id": "dhxLKne8rZil"
      }
    }
  ]
}
